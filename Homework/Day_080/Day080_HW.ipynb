{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 請結合前面的知識與程式碼，比較不同的 optimizer 與 learning rate 組合對訓練的結果與影響\n",
    "### 常見的 optimizer 包含\n",
    "* SGD\n",
    "* RMSprop\n",
    "* AdaGrad\n",
    "* Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check gpu status\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adam\n",
    "\n",
    "# Disable GPU\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_shape, output_units=10, num_neurons=[128,64]):\n",
    "    \"\"\"\n",
    "    Build your own model\n",
    "    \"\"\"\n",
    "    model=Sequential()\n",
    "    model.add(Dense(units=input_shape[1], input_dim=input_shape[1],kernel_initializer='normal',activation='relu',name='input'))\n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        model.add(Dense(units=n_units,kernel_initializer='normal',activation='relu',name='hidden'+str(i+1)))\n",
    "    model.add(Dense(units=output_units,kernel_initializer='normal',activation='softmax',name='output'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "\"\"\"\n",
    "Set your required experiment parameters\n",
    "\"\"\"\n",
    "LEARNING_RATE = [1e-1,1e-2,1e-3]\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 256\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "def build_opt(opt,lr):\n",
    "    if opt== 'SGD':\n",
    "        return SGD(lr=lr, nesterov=True, momentum=True)\n",
    "    elif opt== 'RMSprop':\n",
    "        return RMSprop(lr=lr,rho=0.9,epsilon=None,decay=0.0)\n",
    "    elif opt=='Adagrad':\n",
    "        return Adagrad(lr=lr,epsilon=None,decay=0.0)\n",
    "    elif opt== 'Adam':\n",
    "        return Adam(lr=lr,beta_1=0.9,beta_2=0.999,epsilon=None,decay=0.0,amsgrad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "OPTS = ['SGD','RMSprop','Adagrad','Adam']\n",
    "\"\"\"\n",
    "建立你的訓練與實驗迴圈並蒐集資料\n",
    "\"\"\"\n",
    "for lr in LEARNING_RATE:\n",
    "    for opt in OPTS:\n",
    "        keras.backend.clear_session() #把舊的graph清掉\n",
    "        print(f'Current opt = {opt}, lr={lr}\\n')\n",
    "        \n",
    "        model = build_mlp(input_shape=x_train.shape)\n",
    "        model.summary()\n",
    "        \n",
    "        optimizer=build_opt(opt,lr)\n",
    "              \n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "        \n",
    "        model.fit(x_train,y_train,\n",
    "                  epochs=EPOCHS,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  validation_data=(x_test,y_test),\n",
    "                  shuffle=True)\n",
    "              \n",
    "        # collect results\n",
    "        train_loss=model.history.history['loss']\n",
    "        valid_loss=model.history.history['val_loss']\n",
    "        train_acc =model.history.history['acc']\n",
    "        valid_acc =model.history.history['val_acc']\n",
    "        \n",
    "        # create result dictionary\n",
    "        exp_name_tag = 'exp_%s'%str(opt)+str('+lr_')+str(lr)\n",
    "        \n",
    "        results[exp_name_tag]={'train_loss':train_loss,\n",
    "                               'valid_loss':valid_loss,\n",
    "                               'train_acc':train_acc,\n",
    "                               'valid_acc':valid_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "color_bar=['maroon','red','sienna','orange','olive','greenyellow','lime','green','aqua','dodgerblue','mediumblue','slateblue']\n",
    "\"\"\"\n",
    "將實驗結果繪出\n",
    "\"\"\"\n",
    "plt.figure(figsize=(15,10))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train_loss'])),results[cond]['train_loss'],'-',label=cond,color=color_bar[i])\n",
    "plt.title('Loss of training set')\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['valid_loss'])),results[cond]['valid_loss'],'--',label=cond,color=color_bar[i])\n",
    "plt.title('Loss of testing set')\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train_acc'])),results[cond]['train_acc'],'-',label=cond,color=color_bar[i])\n",
    "plt.title('Accuracy of training set')\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['valid_acc'])),results[cond]['valid_acc'],'--',label=cond,color=color_bar[i])\n",
    "plt.title('Accuracy of testing set')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
