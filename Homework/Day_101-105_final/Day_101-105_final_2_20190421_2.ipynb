{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Day_101-105_final_2_20190421_2.ipynb","version":"0.3.2","provenance":[{"file_id":"1h9DP_Wj2uLBGiINjGGeWMF2NNMCmVUpi","timestamp":1555837920550}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"Sxwq9MhD-hdN","colab_type":"code","outputId":"99a0e89e-236d-4392-bad5-eda3ab46196d","executionInfo":{"status":"ok","timestamp":1555849175797,"user_tz":-480,"elapsed":1913,"user":{"displayName":"楊傑","photoUrl":"","userId":"07428092554711625917"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn import datasets\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"wF6bCJGX-hdT","colab_type":"text"},"cell_type":"markdown","source":["目錄tree:\"D:\\3_learn\\9_MachineLearning\\2_ML100-Days_Data\\Final\\image_data\"  \n","├── test/  \n","└── train/    \n","　　├── daisy/    \n","　　├── dandelion/    \n","　　├── rose/    \n","　　├── sunflower/    \n","　　└── tulip/"]},{"metadata":{"id":"BbHIKyqz-hdV","colab_type":"code","outputId":"2a3fe587-baed-4a2a-e1cf-856a5279590c","executionInfo":{"status":"ok","timestamp":1555849176128,"user_tz":-480,"elapsed":2221,"user":{"displayName":"楊傑","photoUrl":"","userId":"07428092554711625917"}},"colab":{"base_uri":"https://localhost:8080/","height":100}},"cell_type":"code","source":["# 設定資料路徑\n","train_path = \"D:/image_data/train\" \n","test_path = \"D:/image_data/test\" \n","\n","# 圖形預處理\n","# image augmentation + 從directory feed資料\n","train_datagen = ImageDataGenerator(\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2)\n","\n","train_batches = train_datagen.flow_from_directory(\n","    train_path, target_size = (32,32), \n","    classes = ['daisy','dandelion','rose','sunflower','tulip'], \n","    batch_size=10,\n","    subset = 'training')\n","print(train_batches.image_shape)\n","\n","valid_batches = train_datagen.flow_from_directory(\n","    train_path, target_size = (32,32), \n","    classes = ['daisy','dandelion','rose','sunflower','tulip'], \n","    batch_size = 10,\n","    subset = 'validation')\n","print(valid_batches.image_shape)\n","print(train_batches)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 2260 images belonging to 5 classes.\n","(32, 32, 3)\n","Found 563 images belonging to 5 classes.\n","(32, 32, 3)\n","<keras_preprocessing.image.directory_iterator.DirectoryIterator object at 0x000001D6146EE940>\n"],"name":"stdout"}]},{"metadata":{"id":"oaCI0ivs-hdb","colab_type":"code","outputId":"e764dcf4-21d1-4acd-9109-9db66448069c","executionInfo":{"status":"ok","timestamp":1555849264479,"user_tz":-480,"elapsed":90556,"user":{"displayName":"楊傑","photoUrl":"","userId":"07428092554711625917"}},"colab":{"base_uri":"https://localhost:8080/","height":1221}},"cell_type":"code","source":["model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                 input_shape=(32, 32, 3)))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(5))\n","model.add(Activation('softmax'))\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(),\n","              metrics=['accuracy'])\n","\n","\n","STEP_SIZE_TRAIN = train_batches.samples // train_batches.batch_size\n","STEP_SIZE_VALID = valid_batches.samples // valid_batches.batch_size\n","\n","history = model.fit_generator(generator = train_batches, \n","                                  steps_per_epoch = STEP_SIZE_TRAIN, \n","                                  validation_data = valid_batches,\n","                                  validation_steps = STEP_SIZE_VALID, \n","                                  epochs = 10, verbose = 1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 30, 30, 32)        0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 15, 15, 64)        0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 2304)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               1180160   \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 512)               0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 5)                 2565      \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 5)                 0         \n","=================================================================\n","Total params: 1,248,293\n","Trainable params: 1,248,293\n","Non-trainable params: 0\n","_________________________________________________________________\n","WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/10\n","226/226 [==============================] - 10s 46ms/step - loss: 1.4787 - acc: 0.3230 - val_loss: 1.3876 - val_acc: 0.3732\n","Epoch 2/10\n","226/226 [==============================] - 7s 30ms/step - loss: 1.3203 - acc: 0.3947 - val_loss: 1.2533 - val_acc: 0.4141\n","Epoch 3/10\n","226/226 [==============================] - 7s 29ms/step - loss: 1.2402 - acc: 0.4540 - val_loss: 1.2205 - val_acc: 0.4629\n","Epoch 4/10\n","226/226 [==============================] - 7s 30ms/step - loss: 1.1702 - acc: 0.5053 - val_loss: 1.1557 - val_acc: 0.5208\n","Epoch 5/10\n","226/226 [==============================] - 7s 31ms/step - loss: 1.1343 - acc: 0.5367 - val_loss: 1.0738 - val_acc: 0.5714\n","Epoch 6/10\n","226/226 [==============================] - 7s 30ms/step - loss: 1.0921 - acc: 0.5571 - val_loss: 1.0703 - val_acc: 0.5805\n","Epoch 7/10\n","226/226 [==============================] - 7s 30ms/step - loss: 1.0509 - acc: 0.5792 - val_loss: 1.1047 - val_acc: 0.5714\n","Epoch 8/10\n","226/226 [==============================] - 7s 30ms/step - loss: 1.0439 - acc: 0.5929 - val_loss: 1.0903 - val_acc: 0.5750\n","Epoch 9/10\n","226/226 [==============================] - 7s 30ms/step - loss: 0.9788 - acc: 0.6204 - val_loss: 0.9928 - val_acc: 0.6094\n","Epoch 10/10\n","226/226 [==============================] - 7s 30ms/step - loss: 0.9874 - acc: 0.6420 - val_loss: 1.0122 - val_acc: 0.5986\n"],"name":"stdout"}]},{"metadata":{"id":"-X20EPuL-hdi","colab_type":"code","outputId":"c3393a65-92d6-4b0e-9259-c4b6d0df11f7","executionInfo":{"status":"ok","timestamp":1555849264486,"user_tz":-480,"elapsed":90548,"user":{"displayName":"楊傑","photoUrl":"","userId":"07428092554711625917"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"cell_type":"code","source":["test_path = \"D:/image_data/test\" \n","test_batches = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path, target_size=(32,32), batch_size=1, shuffle = False)\n","\n","predictions = model.predict_generator(test_batches, steps=test_batches.samples, verbose=0)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 2000 images belonging to 1 classes.\n"],"name":"stdout"}]},{"metadata":{"id":"Yty7I7olFs_p","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","\n","predicted_class_indices = np.argmax(predictions, axis=1)\n","test_filenames, test_labels = test_batches.filenames, predicted_class_indices\n","\n","# 處理檔名: 以斜線('\\\\'或'/')分開(.split)，回傳最後值(.pop), 由右邊用'.'分開取第二個值(index=1, 最右邊index=0為副檔名)\n","def getFileNameWithoutExtension(path):\n","  return path.split('\\\\').pop().split('/').pop().rsplit('.', 1)[0]\n","\n","test_filenames_list = []\n","for item in test_filenames:\n","  test_filenames_list.append(getFileNameWithoutExtension(item))\n","\n","test_labels_list = []\n","for item in test_labels:\n","  test_labels_list.append(str(item))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XHHClhY1NSuk","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","dataset1 = pd.DataFrame(test_filenames_list)\n","dataset1.columns=['id']\n","dataset2 = pd.DataFrame(test_labels_list)\n","dataset2.columns=['flower_class']\n","\n","submission = pd.concat([dataset1, dataset2], axis=1)\n","\n","submission.to_csv('D:/image_data/submission.csv', index = False)"],"execution_count":0,"outputs":[]}]}