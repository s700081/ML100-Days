{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Day_101-105_final_8_20190423_2.ipynb","version":"0.3.2","provenance":[{"file_id":"1h9DP_Wj2uLBGiINjGGeWMF2NNMCmVUpi","timestamp":1555837920550}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"Sxwq9MhD-hdN","colab_type":"code","outputId":"f777815a-62f5-4e59-ef83-0fabb699a99d","executionInfo":{"status":"ok","timestamp":1556037091381,"user_tz":-480,"elapsed":2134,"user":{"displayName":"楊傑","photoUrl":"","userId":"07428092554711625917"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn import datasets\n","\n","from keras.applications.resnet50 import ResNet50 # 這是從 resnet_builder.py 中直接 import 撰寫好的 resnet 函數\n","from keras.models import Model\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"wF6bCJGX-hdT","colab_type":"text"},"cell_type":"markdown","source":["目錄tree:\"D:\\3_learn\\9_MachineLearning\\2_ML100-Days_Data\\Final\\image_data\"  \n","├── test/  \n","└── train/    \n","　　├── daisy/    \n","　　├── dandelion/    \n","　　├── rose/    \n","　　├── sunflower/    \n","　　└── tulip/"]},{"metadata":{"id":"BbHIKyqz-hdV","colab_type":"code","outputId":"bdf1d05e-86f5-4d97-e28e-8494a851c40b","executionInfo":{"status":"ok","timestamp":1556037091721,"user_tz":-480,"elapsed":2461,"user":{"displayName":"楊傑","photoUrl":"","userId":"07428092554711625917"}},"colab":{"base_uri":"https://localhost:8080/","height":167}},"cell_type":"code","source":["# 設定資料路徑\n","train_path = \"D:/image_data/train\" \n","test_path = \"D:/image_data/test\" \n","\n","# 影像大小\n","IMAGE_SIZE = (256, 256)\n","# 影像類別數，共有 5 個類別\n","NUM_CLASSES = 5\n","# 若 GPU 記憶體不足，可調降 batch size 或凍結更多層網路\n","BATCH_SIZE = 8\n","# 凍結網路層數\n","FREEZE_LAYERS = 2\n","# Epoch 數\n","NUM_EPOCHS = 40\n","# 模型輸出儲存的檔案\n","WEIGHTS_FINAL = 'model-resnet50-final.h5'\n","\n","# 圖形預處理\n","# image augmentation + 從directory feed資料\n","train_datagen = ImageDataGenerator(\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True)\n","\n","train_batches = train_datagen.flow_from_directory(\n","    train_path, target_size = IMAGE_SIZE, \n","    classes = ['daisy','dandelion','rose','sunflower','tulip'], \n","    batch_size = BATCH_SIZE,\n","    shuffle = True)\n","print(train_batches.image_shape)\n","\n","valid_datagen = ImageDataGenerator(\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2)\n","valid_batches = valid_datagen.flow_from_directory(\n","    train_path, target_size = IMAGE_SIZE, \n","    classes = ['daisy','dandelion','rose','sunflower','tulip'], \n","    batch_size = BATCH_SIZE,\n","    shuffle = True,\n","    subset = 'validation')\n","print(valid_batches.image_shape)\n","\n","for cls, idx in train_batches.class_indices.items():\n","    print('Class #{} = {}'.format(idx, cls))\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 2823 images belonging to 5 classes.\n","(256, 256, 3)\n","Found 563 images belonging to 5 classes.\n","(256, 256, 3)\n","Class #0 = daisy\n","Class #1 = dandelion\n","Class #2 = rose\n","Class #3 = sunflower\n","Class #4 = tulip\n"],"name":"stdout"}]},{"metadata":{"id":"oaCI0ivs-hdb","colab_type":"code","outputId":"a2269d9e-2698-4e18-ff94-4facccec16b3","executionInfo":{"status":"ok","timestamp":1556039522509,"user_tz":-480,"elapsed":2433232,"user":{"displayName":"楊傑","photoUrl":"","userId":"07428092554711625917"}},"colab":{"base_uri":"https://localhost:8080/","height":7845}},"cell_type":"code","source":["# 以訓練好的 ResNet50 為基礎來建立模型\n","# 捨棄 ResNet50 頂層的 fully connected layers\n","net = ResNet50(include_top = False, weights = 'imagenet', input_tensor = None,\n","               input_shape = (IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n","x = net.output\n","x = Flatten()(x)\n","\n","# 增加 DropOut layer\n","x = Dropout(0.5)(x)\n","\n","# 增加 Dense layer，以 softmax 產生個類別的機率值\n","output_layer = Dense(NUM_CLASSES, activation='softmax', name='softmax')(x)\n","\n","# 設定凍結與要進行訓練的網路層\n","model = Model(inputs = net.input, outputs=output_layer)\n","for layer in model.layers[:FREEZE_LAYERS]:\n","    layer.trainable = False\n","for layer in model.layers[FREEZE_LAYERS:]:\n","    layer.trainable = True\n","    \n","model.compile(loss = 'categorical_crossentropy',\n","              optimizer = Adam(lr=1e-5),\n","              metrics = ['accuracy'])\n","\n","model.summary()\n","\n","STEP_SIZE_TRAIN = train_batches.samples // train_batches.batch_size\n","STEP_SIZE_VALID = valid_batches.samples // valid_batches.batch_size\n","\n","history = model.fit_generator(generator = train_batches, \n","                                  steps_per_epoch = STEP_SIZE_TRAIN, \n","                                  validation_data = valid_batches,\n","                                  validation_steps = STEP_SIZE_VALID, \n","                                  epochs = NUM_EPOCHS, verbose = 1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1 (Conv2D)                  (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","bn_conv1 (BatchNormalization)   (None, 128, 128, 64) 256         conv1[0][0]                      \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 128, 128, 64) 0           bn_conv1[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","res2a_branch2a (Conv2D)         (None, 64, 64, 64)   4160        max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","bn2a_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 64, 64, 64)   0           bn2a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","bn2a_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 64, 64, 64)   0           bn2a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","res2a_branch1 (Conv2D)          (None, 64, 64, 256)  16640       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","bn2a_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn2a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res2a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 64, 64, 256)  0           bn2a_branch2c[0][0]              \n","                                                                 bn2a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 64, 64, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","res2b_branch2a (Conv2D)         (None, 64, 64, 64)   16448       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 64, 64, 64)   0           bn2b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 64, 64, 64)   0           bn2b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 64, 64, 256)  0           bn2b_branch2c[0][0]              \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 64, 64, 256)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","res2c_branch2a (Conv2D)         (None, 64, 64, 64)   16448       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 64, 64, 64)   0           bn2c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 64, 64, 64)   0           bn2c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 64, 64, 256)  0           bn2c_branch2c[0][0]              \n","                                                                 activation_7[0][0]               \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 64, 64, 256)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","res3a_branch2a (Conv2D)         (None, 32, 32, 128)  32896       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 32, 32, 128)  0           bn3a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_11[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 32, 32, 128)  0           bn3a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch1 (Conv2D)          (None, 32, 32, 512)  131584      activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn3a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res3a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 32, 32, 512)  0           bn3a_branch2c[0][0]              \n","                                                                 bn3a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 32, 32, 512)  0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","res3b_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 32, 32, 128)  0           bn3b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_14[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 32, 32, 128)  0           bn3b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 32, 32, 512)  0           bn3b_branch2c[0][0]              \n","                                                                 activation_13[0][0]              \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 32, 32, 512)  0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","res3c_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 32, 32, 128)  0           bn3c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_17[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 32, 32, 128)  0           bn3c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 32, 32, 512)  0           bn3c_branch2c[0][0]              \n","                                                                 activation_16[0][0]              \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 32, 32, 512)  0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","res3d_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 32, 32, 128)  0           bn3d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 32, 32, 128)  0           bn3d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 32, 32, 512)  0           bn3d_branch2c[0][0]              \n","                                                                 activation_19[0][0]              \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 32, 32, 512)  0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","res4a_branch2a (Conv2D)         (None, 16, 16, 256)  131328      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 16, 16, 256)  0           bn4a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 16, 16, 256)  0           bn4a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch1 (Conv2D)          (None, 16, 16, 1024) 525312      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn4a_branch1 (BatchNormalizatio (None, 16, 16, 1024) 4096        res4a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 16, 16, 1024) 0           bn4a_branch2c[0][0]              \n","                                                                 bn4a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 16, 16, 1024) 0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","res4b_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 16, 16, 256)  0           bn4b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_26[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 16, 16, 256)  0           bn4b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_27[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 16, 16, 1024) 0           bn4b_branch2c[0][0]              \n","                                                                 activation_25[0][0]              \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 16, 16, 1024) 0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","res4c_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 16, 16, 256)  0           bn4c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_29[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 16, 16, 256)  0           bn4c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_30[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 16, 16, 1024) 0           bn4c_branch2c[0][0]              \n","                                                                 activation_28[0][0]              \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 16, 16, 1024) 0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","res4d_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 16, 16, 256)  0           bn4d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_32[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 16, 16, 256)  0           bn4d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_33[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 16, 16, 1024) 0           bn4d_branch2c[0][0]              \n","                                                                 activation_31[0][0]              \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 16, 16, 1024) 0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","res4e_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_34[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4e_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 16, 16, 256)  0           bn4e_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_35[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4e_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 16, 16, 256)  0           bn4e_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4e_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 16, 16, 1024) 0           bn4e_branch2c[0][0]              \n","                                                                 activation_34[0][0]              \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 16, 16, 1024) 0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","res4f_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4f_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 16, 16, 256)  0           bn4f_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4f_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 16, 16, 256)  0           bn4f_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_39[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4f_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 16, 16, 1024) 0           bn4f_branch2c[0][0]              \n","                                                                 activation_37[0][0]              \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 16, 16, 1024) 0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","res5a_branch2a (Conv2D)         (None, 8, 8, 512)    524800      activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 8, 8, 512)    0           bn5a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_41[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 8, 8, 512)    0           bn5a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_42[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch1 (Conv2D)          (None, 8, 8, 2048)   2099200     activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn5a_branch1 (BatchNormalizatio (None, 8, 8, 2048)   8192        res5a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 8, 8, 2048)   0           bn5a_branch2c[0][0]              \n","                                                                 bn5a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 8, 8, 2048)   0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","res5b_branch2a (Conv2D)         (None, 8, 8, 512)    1049088     activation_43[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 8, 8, 512)    0           bn5b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_44[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 8, 8, 512)    0           bn5b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_45[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 8, 8, 2048)   0           bn5b_branch2c[0][0]              \n","                                                                 activation_43[0][0]              \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 8, 8, 2048)   0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","res5c_branch2a (Conv2D)         (None, 8, 8, 512)    1049088     activation_46[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 8, 8, 512)    0           bn5c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_47[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 8, 8, 512)    0           bn5c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_48[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 8, 8, 2048)   0           bn5c_branch2c[0][0]              \n","                                                                 activation_46[0][0]              \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 8, 8, 2048)   0           add_16[0][0]                     \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 131072)       0           activation_49[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 131072)       0           flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","softmax (Dense)                 (None, 5)            655365      dropout_1[0][0]                  \n","==================================================================================================\n","Total params: 24,243,077\n","Trainable params: 24,189,957\n","Non-trainable params: 53,120\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/40\n","352/352 [==============================] - 75s 212ms/step - loss: 2.5240 - acc: 0.3917 - val_loss: 0.9782 - val_acc: 0.6964\n","Epoch 2/40\n","352/352 [==============================] - 60s 171ms/step - loss: 1.4233 - acc: 0.6286 - val_loss: 0.6370 - val_acc: 0.8090\n","Epoch 3/40\n","352/352 [==============================] - 60s 171ms/step - loss: 1.1183 - acc: 0.7076 - val_loss: 0.5239 - val_acc: 0.8432\n","Epoch 4/40\n","352/352 [==============================] - 60s 170ms/step - loss: 0.9651 - acc: 0.7496 - val_loss: 0.4129 - val_acc: 0.8667\n","Epoch 5/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.8531 - acc: 0.7751 - val_loss: 0.3353 - val_acc: 0.8829\n","Epoch 6/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.7724 - acc: 0.7946 - val_loss: 0.3889 - val_acc: 0.8757\n","Epoch 7/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.6949 - acc: 0.8110 - val_loss: 0.2996 - val_acc: 0.9171\n","Epoch 8/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.6505 - acc: 0.8206 - val_loss: 0.2522 - val_acc: 0.9261\n","Epoch 9/40\n","352/352 [==============================] - 60s 170ms/step - loss: 0.5900 - acc: 0.8313 - val_loss: 0.2377 - val_acc: 0.9369\n","Epoch 10/40\n","352/352 [==============================] - 59s 169ms/step - loss: 0.5215 - acc: 0.8448 - val_loss: 0.2729 - val_acc: 0.9189\n","Epoch 11/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.4996 - acc: 0.8536 - val_loss: 0.1389 - val_acc: 0.9495\n","Epoch 12/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.4845 - acc: 0.8621 - val_loss: 0.1550 - val_acc: 0.9514\n","Epoch 13/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.4106 - acc: 0.8781 - val_loss: 0.1423 - val_acc: 0.9568\n","Epoch 14/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.4002 - acc: 0.8782 - val_loss: 0.1436 - val_acc: 0.9387\n","Epoch 15/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.3795 - acc: 0.8878 - val_loss: 0.1214 - val_acc: 0.9658\n","Epoch 16/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.3173 - acc: 0.9002 - val_loss: 0.1363 - val_acc: 0.9514\n","Epoch 17/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.3310 - acc: 0.8984 - val_loss: 0.1354 - val_acc: 0.9532\n","Epoch 18/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.3066 - acc: 0.9051 - val_loss: 0.1336 - val_acc: 0.9604\n","Epoch 19/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.2688 - acc: 0.9108 - val_loss: 0.0874 - val_acc: 0.9640\n","Epoch 20/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.2640 - acc: 0.9186 - val_loss: 0.0893 - val_acc: 0.9694\n","Epoch 21/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.2381 - acc: 0.9289 - val_loss: 0.0573 - val_acc: 0.9820\n","Epoch 22/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.2234 - acc: 0.9275 - val_loss: 0.0746 - val_acc: 0.9802\n","Epoch 23/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.2245 - acc: 0.9325 - val_loss: 0.0348 - val_acc: 0.9910\n","Epoch 24/40\n","352/352 [==============================] - 59s 167ms/step - loss: 0.2084 - acc: 0.9357 - val_loss: 0.0822 - val_acc: 0.9712\n","Epoch 25/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.2281 - acc: 0.9251 - val_loss: 0.0597 - val_acc: 0.9784\n","Epoch 26/40\n","352/352 [==============================] - 59s 167ms/step - loss: 0.1638 - acc: 0.9478 - val_loss: 0.0651 - val_acc: 0.9766\n","Epoch 27/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.1804 - acc: 0.9425 - val_loss: 0.0685 - val_acc: 0.9856\n","Epoch 28/40\n","352/352 [==============================] - 59s 169ms/step - loss: 0.1679 - acc: 0.9414 - val_loss: 0.0528 - val_acc: 0.9784\n","Epoch 29/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.1648 - acc: 0.9485 - val_loss: 0.0431 - val_acc: 0.9838\n","Epoch 30/40\n","352/352 [==============================] - 59s 167ms/step - loss: 0.1571 - acc: 0.9485 - val_loss: 0.0368 - val_acc: 0.9874\n","Epoch 31/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.1367 - acc: 0.9545 - val_loss: 0.0462 - val_acc: 0.9856\n","Epoch 32/40\n","352/352 [==============================] - 59s 167ms/step - loss: 0.1363 - acc: 0.9556 - val_loss: 0.0217 - val_acc: 0.9910\n","Epoch 33/40\n","352/352 [==============================] - 59s 167ms/step - loss: 0.1184 - acc: 0.9606 - val_loss: 0.0486 - val_acc: 0.9874\n","Epoch 34/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.1261 - acc: 0.9581 - val_loss: 0.0168 - val_acc: 0.9928\n","Epoch 35/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.1234 - acc: 0.9627 - val_loss: 0.0251 - val_acc: 0.9892\n","Epoch 36/40\n","352/352 [==============================] - 59s 167ms/step - loss: 0.1233 - acc: 0.9616 - val_loss: 0.0086 - val_acc: 0.9982\n","Epoch 37/40\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0975 - acc: 0.9662 - val_loss: 0.0299 - val_acc: 0.9892\n","Epoch 38/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.0871 - acc: 0.9684 - val_loss: 0.0272 - val_acc: 0.9910\n","Epoch 39/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.0966 - acc: 0.9695 - val_loss: 0.0199 - val_acc: 0.9946\n","Epoch 40/40\n","352/352 [==============================] - 59s 168ms/step - loss: 0.1087 - acc: 0.9670 - val_loss: 0.0202 - val_acc: 0.9928\n"],"name":"stdout"}]},{"metadata":{"id":"-X20EPuL-hdi","colab_type":"code","outputId":"a87c6506-2c42-41ca-85b6-52a0b4acc3ef","executionInfo":{"status":"ok","timestamp":1556039522516,"user_tz":-480,"elapsed":2433223,"user":{"displayName":"楊傑","photoUrl":"","userId":"07428092554711625917"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"cell_type":"code","source":["test_path = \"D:/image_data/test\" \n","test_batches = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path, target_size=IMAGE_SIZE, batch_size=1, shuffle = False)\n","\n","predictions = model.predict_generator(test_batches, steps=test_batches.samples, verbose=1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 2000 images belonging to 1 classes.\n","2000/2000 [==============================] - 32s 16ms/step\n"],"name":"stdout"}]},{"metadata":{"id":"Yty7I7olFs_p","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","\n","predicted_class_indices = np.argmax(predictions, axis=1)\n","test_filenames, test_labels = test_batches.filenames, predicted_class_indices\n","\n","# 處理檔名: 以斜線('\\\\'或'/')分開(.split)，回傳最後值(.pop), 由右邊用'.'分開取第二個值(index=1, 最右邊index=0為副檔名)\n","def getFileNameWithoutExtension(path):\n","  return path.split('\\\\').pop().split('/').pop().rsplit('.', 1)[0]\n","\n","test_filenames_list = []\n","for item in test_filenames:\n","  test_filenames_list.append(getFileNameWithoutExtension(item))\n","\n","test_labels_list = []\n","for item in test_labels:\n","  test_labels_list.append(str(item))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XHHClhY1NSuk","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","dataset1 = pd.DataFrame(test_filenames_list)\n","dataset1.columns=['id']\n","dataset2 = pd.DataFrame(test_labels_list)\n","dataset2.columns=['flower_class']\n","\n","submission = pd.concat([dataset1, dataset2], axis=1)\n","\n","submission.to_csv('D:/image_data/submission_8-1.csv', index = False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"R8JAFcgv91ck","colab_type":"code","outputId":"d0537623-294a-4ae7-c47b-bc285676f2e6","executionInfo":{"status":"ok","timestamp":1556048881733,"user_tz":-480,"elapsed":11792384,"user":{"displayName":"楊傑","photoUrl":"","userId":"07428092554711625917"}},"colab":{"base_uri":"https://localhost:8080/","height":5436}},"cell_type":"code","source":["history = model.fit_generator(generator = train_batches, \n","                                  steps_per_epoch = STEP_SIZE_TRAIN, \n","                                  validation_data = valid_batches,\n","                                  validation_steps = STEP_SIZE_VALID, \n","                                  epochs = NUM_EPOCHS, verbose = 1)\n","predictions = model.predict_generator(test_batches, steps=test_batches.samples, verbose=1)\n","predicted_class_indices = np.argmax(predictions, axis=1)\n","test_labels_list = []\n","for item in predicted_class_indices:\n","  test_labels_list.append(str(item))\n","dataset2 = pd.DataFrame(test_labels_list)\n","dataset2.columns=['flower_class']\n","submission = pd.concat([dataset1, dataset2], axis=1)\n","submission.to_csv('D:/image_data/submission_8-2.csv', index = False)\n","\n","history = model.fit_generator(generator = train_batches, \n","                                  steps_per_epoch = STEP_SIZE_TRAIN, \n","                                  validation_data = valid_batches,\n","                                  validation_steps = STEP_SIZE_VALID, \n","                                  epochs = NUM_EPOCHS, verbose = 1)\n","predictions = model.predict_generator(test_batches, steps=test_batches.samples, verbose=1)\n","predicted_class_indices = np.argmax(predictions, axis=1)\n","test_labels_list = []\n","for item in predicted_class_indices:\n","  test_labels_list.append(str(item))\n","dataset2 = pd.DataFrame(test_labels_list)\n","dataset2.columns=['flower_class']\n","submission = pd.concat([dataset1, dataset2], axis=1)\n","submission.to_csv('D:/image_data/submission_8-3.csv', index = False)\n","\n","history = model.fit_generator(generator = train_batches, \n","                                  steps_per_epoch = STEP_SIZE_TRAIN, \n","                                  validation_data = valid_batches,\n","                                  validation_steps = STEP_SIZE_VALID, \n","                                  epochs = NUM_EPOCHS, verbose = 1)\n","predictions = model.predict_generator(test_batches, steps=test_batches.samples, verbose=1)\n","predicted_class_indices = np.argmax(predictions, axis=1)\n","test_labels_list = []\n","for item in predicted_class_indices:\n","  test_labels_list.append(str(item))\n","dataset2 = pd.DataFrame(test_labels_list)\n","dataset2.columns=['flower_class']\n","submission = pd.concat([dataset1, dataset2], axis=1)\n","submission.to_csv('D:/image_data/submission_8-4.csv', index = False)\n","\n","history = model.fit_generator(generator = train_batches, \n","                                  steps_per_epoch = STEP_SIZE_TRAIN, \n","                                  validation_data = valid_batches,\n","                                  validation_steps = STEP_SIZE_VALID, \n","                                  epochs = NUM_EPOCHS, verbose = 1)\n","predictions = model.predict_generator(test_batches, steps=test_batches.samples, verbose=1)\n","predicted_class_indices = np.argmax(predictions, axis=1)\n","test_labels_list = []\n","for item in predicted_class_indices:\n","  test_labels_list.append(str(item))\n","dataset2 = pd.DataFrame(test_labels_list)\n","dataset2.columns=['flower_class']\n","submission = pd.concat([dataset1, dataset2], axis=1)\n","submission.to_csv('D:/image_data/submission_8-5.csv', index = False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0982 - acc: 0.9673 - val_loss: 0.0136 - val_acc: 0.9946\n","Epoch 2/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0947 - acc: 0.9701 - val_loss: 0.0264 - val_acc: 0.9892\n","Epoch 3/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.1026 - acc: 0.9698 - val_loss: 0.0131 - val_acc: 0.9946\n","Epoch 4/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0786 - acc: 0.9751 - val_loss: 0.0167 - val_acc: 0.9964\n","Epoch 5/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0730 - acc: 0.9780 - val_loss: 0.0115 - val_acc: 0.9982\n","Epoch 6/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0678 - acc: 0.9779 - val_loss: 0.0083 - val_acc: 0.9964\n","Epoch 7/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0691 - acc: 0.9798 - val_loss: 0.0136 - val_acc: 0.9964\n","Epoch 8/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0625 - acc: 0.9801 - val_loss: 0.0070 - val_acc: 0.9964\n","Epoch 9/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0647 - acc: 0.9815 - val_loss: 0.0043 - val_acc: 1.0000\n","Epoch 10/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0626 - acc: 0.9808 - val_loss: 0.0132 - val_acc: 0.9946\n","Epoch 11/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0644 - acc: 0.9786 - val_loss: 0.0016 - val_acc: 1.0000\n","Epoch 12/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0708 - acc: 0.9773 - val_loss: 0.0081 - val_acc: 0.9964\n","Epoch 13/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0482 - acc: 0.9815 - val_loss: 0.0110 - val_acc: 0.9964\n","Epoch 14/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0519 - acc: 0.9819 - val_loss: 0.0137 - val_acc: 0.9964\n","Epoch 15/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0638 - acc: 0.9808 - val_loss: 0.0118 - val_acc: 0.9964\n","Epoch 16/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0741 - acc: 0.9794 - val_loss: 0.0029 - val_acc: 1.0000\n","Epoch 17/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0627 - acc: 0.9801 - val_loss: 0.0023 - val_acc: 1.0000\n","Epoch 18/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0487 - acc: 0.9840 - val_loss: 0.0052 - val_acc: 0.9982\n","Epoch 19/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0480 - acc: 0.9847 - val_loss: 0.0061 - val_acc: 0.9982\n","Epoch 20/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0504 - acc: 0.9833 - val_loss: 8.7449e-04 - val_acc: 1.0000\n","Epoch 21/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0405 - acc: 0.9872 - val_loss: 0.0014 - val_acc: 1.0000\n","Epoch 22/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0552 - acc: 0.9847 - val_loss: 0.0094 - val_acc: 0.9964\n","Epoch 23/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0489 - acc: 0.9847 - val_loss: 0.0027 - val_acc: 0.9982\n","Epoch 24/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0424 - acc: 0.9886 - val_loss: 0.0042 - val_acc: 0.9982\n","Epoch 25/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0340 - acc: 0.9879 - val_loss: 0.0063 - val_acc: 0.9982\n","Epoch 26/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0455 - acc: 0.9858 - val_loss: 0.0109 - val_acc: 0.9964\n","Epoch 27/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0420 - acc: 0.9897 - val_loss: 0.0067 - val_acc: 0.9964\n","Epoch 28/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0437 - acc: 0.9858 - val_loss: 0.0065 - val_acc: 0.9982\n","Epoch 29/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0355 - acc: 0.9893 - val_loss: 0.0064 - val_acc: 0.9946\n","Epoch 30/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0414 - acc: 0.9869 - val_loss: 0.0120 - val_acc: 0.9964\n","Epoch 31/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0356 - acc: 0.9890 - val_loss: 0.0018 - val_acc: 1.0000\n","Epoch 32/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0457 - acc: 0.9858 - val_loss: 0.0011 - val_acc: 1.0000\n","Epoch 33/40\n","352/352 [==============================] - 58s 166ms/step - loss: 0.0333 - acc: 0.9904 - val_loss: 0.0027 - val_acc: 1.0000\n","Epoch 34/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0411 - acc: 0.9882 - val_loss: 0.0033 - val_acc: 0.9982\n","Epoch 35/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0306 - acc: 0.9901 - val_loss: 0.0029 - val_acc: 0.9982\n","Epoch 36/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0350 - acc: 0.9876 - val_loss: 0.0014 - val_acc: 1.0000\n","Epoch 37/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0352 - acc: 0.9893 - val_loss: 0.0020 - val_acc: 1.0000\n","Epoch 38/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0557 - acc: 0.9869 - val_loss: 0.0010 - val_acc: 1.0000\n","Epoch 39/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0383 - acc: 0.9883 - val_loss: 0.0032 - val_acc: 0.9982\n","Epoch 40/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0283 - acc: 0.9911 - val_loss: 0.0081 - val_acc: 0.9982\n","2000/2000 [==============================] - 24s 12ms/step\n","Epoch 1/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0230 - acc: 0.9908 - val_loss: 2.0302e-04 - val_acc: 1.0000\n","Epoch 2/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0330 - acc: 0.9901 - val_loss: 5.9833e-04 - val_acc: 1.0000\n","Epoch 3/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0199 - acc: 0.9918 - val_loss: 2.6597e-04 - val_acc: 1.0000\n","Epoch 4/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0296 - acc: 0.9922 - val_loss: 4.0452e-04 - val_acc: 1.0000\n","Epoch 5/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0264 - acc: 0.9911 - val_loss: 0.0036 - val_acc: 0.9982\n","Epoch 6/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0352 - acc: 0.9897 - val_loss: 0.0092 - val_acc: 0.9964\n","Epoch 7/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0235 - acc: 0.9918 - val_loss: 2.8585e-04 - val_acc: 1.0000\n","Epoch 8/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0236 - acc: 0.9915 - val_loss: 0.0076 - val_acc: 0.9964\n","Epoch 9/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0139 - acc: 0.9940 - val_loss: 9.5183e-04 - val_acc: 1.0000\n","Epoch 10/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0243 - acc: 0.9929 - val_loss: 8.3523e-04 - val_acc: 1.0000\n","Epoch 11/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0231 - acc: 0.9918 - val_loss: 0.0043 - val_acc: 0.9982\n","Epoch 12/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0296 - acc: 0.9911 - val_loss: 0.0020 - val_acc: 1.0000\n","Epoch 13/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0225 - acc: 0.9911 - val_loss: 4.1079e-05 - val_acc: 1.0000\n","Epoch 14/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0282 - acc: 0.9936 - val_loss: 0.0011 - val_acc: 1.0000\n","Epoch 15/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0161 - acc: 0.9950 - val_loss: 3.1434e-04 - val_acc: 1.0000\n","Epoch 16/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0332 - acc: 0.9886 - val_loss: 5.9055e-04 - val_acc: 1.0000\n","Epoch 17/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0393 - acc: 0.9879 - val_loss: 6.8149e-04 - val_acc: 1.0000\n","Epoch 18/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0241 - acc: 0.9922 - val_loss: 5.7846e-04 - val_acc: 1.0000\n","Epoch 19/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0172 - acc: 0.9933 - val_loss: 3.9203e-04 - val_acc: 1.0000\n","Epoch 20/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0260 - acc: 0.9915 - val_loss: 7.1126e-05 - val_acc: 1.0000\n","Epoch 21/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0203 - acc: 0.9940 - val_loss: 0.0024 - val_acc: 0.9982\n","Epoch 22/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0135 - acc: 0.9957 - val_loss: 1.5960e-04 - val_acc: 1.0000\n","Epoch 23/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0225 - acc: 0.9940 - val_loss: 0.0048 - val_acc: 0.9982\n","Epoch 24/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0277 - acc: 0.9901 - val_loss: 0.0037 - val_acc: 0.9982\n","Epoch 25/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0165 - acc: 0.9954 - val_loss: 0.0056 - val_acc: 0.9982\n","Epoch 26/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0221 - acc: 0.9929 - val_loss: 3.7669e-04 - val_acc: 1.0000\n","Epoch 27/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0128 - acc: 0.9964 - val_loss: 2.1475e-04 - val_acc: 1.0000\n","Epoch 28/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0241 - acc: 0.9925 - val_loss: 0.0048 - val_acc: 0.9964\n","Epoch 29/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0203 - acc: 0.9943 - val_loss: 0.0055 - val_acc: 0.9982\n","Epoch 30/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0211 - acc: 0.9925 - val_loss: 0.0012 - val_acc: 1.0000\n","Epoch 31/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0191 - acc: 0.9950 - val_loss: 0.0014 - val_acc: 1.0000\n","Epoch 32/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0223 - acc: 0.9940 - val_loss: 1.1523e-04 - val_acc: 1.0000\n","Epoch 33/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0184 - acc: 0.9918 - val_loss: 4.2386e-04 - val_acc: 1.0000\n","Epoch 34/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0202 - acc: 0.9950 - val_loss: 0.0062 - val_acc: 0.9982\n","Epoch 35/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0178 - acc: 0.9950 - val_loss: 7.7315e-04 - val_acc: 1.0000\n","Epoch 36/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0308 - acc: 0.9901 - val_loss: 0.0011 - val_acc: 1.0000\n","Epoch 37/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0247 - acc: 0.9940 - val_loss: 6.2937e-04 - val_acc: 1.0000\n","Epoch 38/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0221 - acc: 0.9943 - val_loss: 1.0581e-04 - val_acc: 1.0000\n","Epoch 39/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0188 - acc: 0.9933 - val_loss: 4.8099e-04 - val_acc: 1.0000\n","Epoch 40/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0188 - acc: 0.9936 - val_loss: 6.5366e-04 - val_acc: 1.0000\n","2000/2000 [==============================] - 25s 12ms/step\n","Epoch 1/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0205 - acc: 0.9933 - val_loss: 3.7980e-04 - val_acc: 1.0000\n","Epoch 2/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0145 - acc: 0.9954 - val_loss: 9.3350e-04 - val_acc: 1.0000\n","Epoch 3/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0155 - acc: 0.9950 - val_loss: 4.6319e-04 - val_acc: 1.0000\n","Epoch 4/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0173 - acc: 0.9954 - val_loss: 0.0013 - val_acc: 1.0000\n","Epoch 5/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0183 - acc: 0.9933 - val_loss: 3.3167e-04 - val_acc: 1.0000\n","Epoch 6/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0124 - acc: 0.9954 - val_loss: 6.8334e-04 - val_acc: 1.0000\n","Epoch 7/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0160 - acc: 0.9950 - val_loss: 2.2283e-04 - val_acc: 1.0000\n","Epoch 8/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0246 - acc: 0.9918 - val_loss: 0.0052 - val_acc: 0.9982\n","Epoch 9/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0184 - acc: 0.9943 - val_loss: 3.7304e-04 - val_acc: 1.0000\n","Epoch 10/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0238 - acc: 0.9925 - val_loss: 2.0778e-04 - val_acc: 1.0000\n","Epoch 11/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0153 - acc: 0.9954 - val_loss: 6.5922e-04 - val_acc: 1.0000\n","Epoch 12/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0195 - acc: 0.9925 - val_loss: 8.3509e-05 - val_acc: 1.0000\n","Epoch 13/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0200 - acc: 0.9939 - val_loss: 1.9143e-04 - val_acc: 1.0000\n","Epoch 14/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0118 - acc: 0.9964 - val_loss: 4.0089e-04 - val_acc: 1.0000\n","Epoch 15/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0150 - acc: 0.9968 - val_loss: 0.0102 - val_acc: 0.9982\n","Epoch 16/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0225 - acc: 0.9911 - val_loss: 9.6320e-04 - val_acc: 1.0000\n","Epoch 17/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0192 - acc: 0.9957 - val_loss: 2.6365e-04 - val_acc: 1.0000\n","Epoch 18/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0108 - acc: 0.9972 - val_loss: 6.8720e-04 - val_acc: 1.0000\n","Epoch 19/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0168 - acc: 0.9957 - val_loss: 0.0063 - val_acc: 0.9982\n","Epoch 20/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0188 - acc: 0.9954 - val_loss: 0.0032 - val_acc: 0.9982\n","Epoch 21/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0126 - acc: 0.9947 - val_loss: 0.0055 - val_acc: 0.9982\n","Epoch 22/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0130 - acc: 0.9957 - val_loss: 0.0037 - val_acc: 0.9982\n","Epoch 23/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0120 - acc: 0.9947 - val_loss: 0.0064 - val_acc: 0.9964\n","Epoch 24/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0160 - acc: 0.9943 - val_loss: 0.0026 - val_acc: 0.9982\n","Epoch 25/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0160 - acc: 0.9954 - val_loss: 0.0023 - val_acc: 0.9982\n","Epoch 26/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0159 - acc: 0.9947 - val_loss: 0.0060 - val_acc: 0.9982\n","Epoch 27/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0167 - acc: 0.9961 - val_loss: 0.0018 - val_acc: 1.0000\n","Epoch 28/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0192 - acc: 0.9957 - val_loss: 0.0055 - val_acc: 0.9982\n","Epoch 29/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0207 - acc: 0.9929 - val_loss: 0.0014 - val_acc: 1.0000\n","Epoch 30/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0126 - acc: 0.9961 - val_loss: 0.0044 - val_acc: 0.9964\n","Epoch 31/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0091 - acc: 0.9975 - val_loss: 2.2913e-04 - val_acc: 1.0000\n","Epoch 32/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0095 - acc: 0.9947 - val_loss: 3.9026e-05 - val_acc: 1.0000\n","Epoch 33/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0173 - acc: 0.9940 - val_loss: 9.1249e-05 - val_acc: 1.0000\n","Epoch 34/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0101 - acc: 0.9972 - val_loss: 2.9571e-04 - val_acc: 1.0000\n","Epoch 35/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0135 - acc: 0.9954 - val_loss: 2.0218e-04 - val_acc: 1.0000\n","Epoch 36/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0096 - acc: 0.9957 - val_loss: 8.9582e-06 - val_acc: 1.0000\n","Epoch 37/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0248 - acc: 0.9925 - val_loss: 5.3766e-04 - val_acc: 1.0000\n","Epoch 38/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0166 - acc: 0.9943 - val_loss: 1.8909e-04 - val_acc: 1.0000\n","Epoch 39/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0202 - acc: 0.9947 - val_loss: 1.5403e-05 - val_acc: 1.0000\n","Epoch 40/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0266 - acc: 0.9933 - val_loss: 1.4541e-04 - val_acc: 1.0000\n","2000/2000 [==============================] - 24s 12ms/step\n","Epoch 1/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0167 - acc: 0.9954 - val_loss: 0.0024 - val_acc: 1.0000\n","Epoch 2/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0114 - acc: 0.9964 - val_loss: 9.4268e-05 - val_acc: 1.0000\n","Epoch 3/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0083 - acc: 0.9968 - val_loss: 6.1082e-05 - val_acc: 1.0000\n","Epoch 4/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0164 - acc: 0.9947 - val_loss: 8.9985e-04 - val_acc: 1.0000\n","Epoch 5/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0168 - acc: 0.9964 - val_loss: 1.1687e-04 - val_acc: 1.0000\n","Epoch 6/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0041 - acc: 0.9982 - val_loss: 5.1434e-04 - val_acc: 1.0000\n","Epoch 7/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0084 - acc: 0.9972 - val_loss: 3.2041e-04 - val_acc: 1.0000\n","Epoch 8/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0147 - acc: 0.9936 - val_loss: 5.0507e-06 - val_acc: 1.0000\n","Epoch 9/40\n","352/352 [==============================] - 58s 163ms/step - loss: 0.0134 - acc: 0.9957 - val_loss: 3.0950e-04 - val_acc: 1.0000\n","Epoch 10/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0155 - acc: 0.9954 - val_loss: 0.0054 - val_acc: 0.9982\n","Epoch 11/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0095 - acc: 0.9979 - val_loss: 0.0013 - val_acc: 1.0000\n","Epoch 12/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0127 - acc: 0.9947 - val_loss: 3.4019e-04 - val_acc: 1.0000\n","Epoch 13/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0163 - acc: 0.9957 - val_loss: 7.1898e-04 - val_acc: 1.0000\n","Epoch 14/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0148 - acc: 0.9961 - val_loss: 3.4522e-04 - val_acc: 1.0000\n","Epoch 15/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0197 - acc: 0.9940 - val_loss: 1.6231e-04 - val_acc: 1.0000\n","Epoch 16/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0113 - acc: 0.9975 - val_loss: 4.6117e-05 - val_acc: 1.0000\n","Epoch 17/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0223 - acc: 0.9954 - val_loss: 9.1538e-05 - val_acc: 1.0000\n","Epoch 18/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0158 - acc: 0.9950 - val_loss: 1.1851e-05 - val_acc: 1.0000\n","Epoch 19/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0169 - acc: 0.9947 - val_loss: 0.0290 - val_acc: 0.9982\n","Epoch 20/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0149 - acc: 0.9975 - val_loss: 2.4462e-05 - val_acc: 1.0000\n","Epoch 21/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0094 - acc: 0.9968 - val_loss: 2.1299e-05 - val_acc: 1.0000\n","Epoch 22/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0162 - acc: 0.9954 - val_loss: 1.4033e-04 - val_acc: 1.0000\n","Epoch 23/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0070 - acc: 0.9972 - val_loss: 4.5546e-04 - val_acc: 1.0000\n","Epoch 24/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0222 - acc: 0.9943 - val_loss: 5.0274e-05 - val_acc: 1.0000\n","Epoch 25/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0211 - acc: 0.9957 - val_loss: 0.0054 - val_acc: 0.9982\n","Epoch 26/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0114 - acc: 0.9957 - val_loss: 2.0395e-04 - val_acc: 1.0000\n","Epoch 27/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0088 - acc: 0.9986 - val_loss: 5.4611e-05 - val_acc: 1.0000\n","Epoch 28/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0178 - acc: 0.9961 - val_loss: 0.0059 - val_acc: 0.9982\n","Epoch 29/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0118 - acc: 0.9950 - val_loss: 0.0020 - val_acc: 0.9982\n","Epoch 30/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0157 - acc: 0.9964 - val_loss: 0.0041 - val_acc: 0.9982\n","Epoch 31/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0277 - acc: 0.9918 - val_loss: 4.1327e-05 - val_acc: 1.0000\n","Epoch 32/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0133 - acc: 0.9975 - val_loss: 0.0010 - val_acc: 1.0000\n","Epoch 33/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0155 - acc: 0.9961 - val_loss: 3.3811e-04 - val_acc: 1.0000\n","Epoch 34/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0118 - acc: 0.9961 - val_loss: 0.0012 - val_acc: 1.0000\n","Epoch 35/40\n","352/352 [==============================] - 58s 165ms/step - loss: 0.0113 - acc: 0.9975 - val_loss: 0.0038 - val_acc: 0.9982\n","Epoch 36/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0093 - acc: 0.9982 - val_loss: 0.0013 - val_acc: 1.0000\n","Epoch 37/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0088 - acc: 0.9982 - val_loss: 6.7301e-04 - val_acc: 1.0000\n","Epoch 38/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0193 - acc: 0.9938 - val_loss: 1.7784e-04 - val_acc: 1.0000\n","Epoch 39/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0102 - acc: 0.9961 - val_loss: 5.1853e-05 - val_acc: 1.0000\n","Epoch 40/40\n","352/352 [==============================] - 58s 164ms/step - loss: 0.0099 - acc: 0.9961 - val_loss: 0.0010 - val_acc: 1.0000\n","2000/2000 [==============================] - 24s 12ms/step\n"],"name":"stdout"}]}]}