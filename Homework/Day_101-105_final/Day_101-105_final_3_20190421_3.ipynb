{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Day_101-105_final_3_20190421_3.ipynb","version":"0.3.2","provenance":[{"file_id":"1h9DP_Wj2uLBGiINjGGeWMF2NNMCmVUpi","timestamp":1555837920550}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"Sxwq9MhD-hdN","colab_type":"code","outputId":"0dd11e7d-42a2-4daa-c52d-525add24a4fc","executionInfo":{"status":"ok","timestamp":1555849346579,"user_tz":-480,"elapsed":1945,"user":{"displayName":"楊傑","photoUrl":"","userId":"07428092554711625917"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn import datasets\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"wF6bCJGX-hdT","colab_type":"text"},"cell_type":"markdown","source":["目錄tree:\"D:\\3_learn\\9_MachineLearning\\2_ML100-Days_Data\\Final\\image_data\"  \n","├── test/  \n","└── train/    \n","　　├── daisy/    \n","　　├── dandelion/    \n","　　├── rose/    \n","　　├── sunflower/    \n","　　└── tulip/"]},{"metadata":{"id":"BbHIKyqz-hdV","colab_type":"code","outputId":"a5acf008-0572-4bd9-ee29-9a9284be4ef5","executionInfo":{"status":"ok","timestamp":1555849346906,"user_tz":-480,"elapsed":2252,"user":{"displayName":"楊傑","photoUrl":"","userId":"07428092554711625917"}},"colab":{"base_uri":"https://localhost:8080/","height":100}},"cell_type":"code","source":["# 設定資料路徑\n","train_path = \"D:/image_data/train\" \n","test_path = \"D:/image_data/test\" \n","\n","# 圖形預處理\n","# image augmentation + 從directory feed資料\n","train_datagen = ImageDataGenerator(\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2)\n","\n","train_batches = train_datagen.flow_from_directory(\n","    train_path, target_size = (32,32), \n","    classes = ['daisy','dandelion','rose','sunflower','tulip'], \n","    batch_size=10,\n","    subset = 'training')\n","print(train_batches.image_shape)\n","\n","valid_batches = train_datagen.flow_from_directory(\n","    train_path, target_size = (32,32), \n","    classes = ['daisy','dandelion','rose','sunflower','tulip'], \n","    batch_size = 10,\n","    subset = 'validation')\n","print(valid_batches.image_shape)\n","print(train_batches)\n","\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Found 2260 images belonging to 5 classes.\n","(32, 32, 3)\n","Found 563 images belonging to 5 classes.\n","(32, 32, 3)\n","<keras_preprocessing.image.directory_iterator.DirectoryIterator object at 0x0000020A785DB940>\n"],"name":"stdout"}]},{"metadata":{"id":"oaCI0ivs-hdb","colab_type":"code","outputId":"32dbddac-9b51-4274-cbdc-a9793a49e9de","executionInfo":{"status":"ok","timestamp":1555849552315,"user_tz":-480,"elapsed":207644,"user":{"displayName":"楊傑","photoUrl":"","userId":"07428092554711625917"}},"colab":{"base_uri":"https://localhost:8080/","height":1890}},"cell_type":"code","source":["model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                 input_shape=(32, 32, 3)))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(5))\n","model.add(Activation('softmax'))\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(),\n","              metrics=['accuracy'])\n","\n","\n","STEP_SIZE_TRAIN = train_batches.samples // train_batches.batch_size\n","STEP_SIZE_VALID = valid_batches.samples // valid_batches.batch_size\n","\n","history = model.fit_generator(generator = train_batches, \n","                                  steps_per_epoch = STEP_SIZE_TRAIN, \n","                                  validation_data = valid_batches,\n","                                  validation_steps = STEP_SIZE_VALID, \n","                                  epochs = 30, verbose = 1)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 30, 30, 32)        0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 15, 15, 64)        0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 2304)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               1180160   \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 512)               0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 5)                 2565      \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 5)                 0         \n","=================================================================\n","Total params: 1,248,293\n","Trainable params: 1,248,293\n","Non-trainable params: 0\n","_________________________________________________________________\n","WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/30\n","226/226 [==============================] - 10s 45ms/step - loss: 1.4369 - acc: 0.3650 - val_loss: 1.3763 - val_acc: 0.3732\n","Epoch 2/30\n","226/226 [==============================] - 7s 29ms/step - loss: 1.2646 - acc: 0.4425 - val_loss: 1.2370 - val_acc: 0.4611\n","Epoch 3/30\n","226/226 [==============================] - 7s 30ms/step - loss: 1.1984 - acc: 0.4836 - val_loss: 1.1924 - val_acc: 0.4901\n","Epoch 4/30\n","226/226 [==============================] - 7s 29ms/step - loss: 1.1249 - acc: 0.5252 - val_loss: 1.0719 - val_acc: 0.6166\n","Epoch 5/30\n","226/226 [==============================] - 7s 30ms/step - loss: 1.0858 - acc: 0.5726 - val_loss: 1.0244 - val_acc: 0.6058\n","Epoch 6/30\n","226/226 [==============================] - 7s 30ms/step - loss: 1.0316 - acc: 0.5947 - val_loss: 1.0505 - val_acc: 0.6130\n","Epoch 7/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.9901 - acc: 0.6159 - val_loss: 0.9915 - val_acc: 0.6257\n","Epoch 8/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.9475 - acc: 0.6323 - val_loss: 0.9649 - val_acc: 0.6528\n","Epoch 9/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.9285 - acc: 0.6509 - val_loss: 0.8921 - val_acc: 0.6763\n","Epoch 10/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.9242 - acc: 0.6566 - val_loss: 0.9244 - val_acc: 0.6618\n","Epoch 11/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.8957 - acc: 0.6611 - val_loss: 1.0135 - val_acc: 0.6094\n","Epoch 12/30\n","226/226 [==============================] - 7s 29ms/step - loss: 0.8969 - acc: 0.6522 - val_loss: 0.8988 - val_acc: 0.6600\n","Epoch 13/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.8974 - acc: 0.6717 - val_loss: 0.9358 - val_acc: 0.6781\n","Epoch 14/30\n","226/226 [==============================] - 7s 29ms/step - loss: 0.8688 - acc: 0.6783 - val_loss: 0.8693 - val_acc: 0.6745\n","Epoch 15/30\n","226/226 [==============================] - 7s 29ms/step - loss: 0.8560 - acc: 0.6686 - val_loss: 0.9087 - val_acc: 0.6347\n","Epoch 16/30\n","226/226 [==============================] - 7s 29ms/step - loss: 0.8594 - acc: 0.6708 - val_loss: 0.9036 - val_acc: 0.6618\n","Epoch 17/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.8537 - acc: 0.6801 - val_loss: 0.9008 - val_acc: 0.6817\n","Epoch 18/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.8273 - acc: 0.6792 - val_loss: 0.8602 - val_acc: 0.6727\n","Epoch 19/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.8274 - acc: 0.6889 - val_loss: 0.8486 - val_acc: 0.6980\n","Epoch 20/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.8027 - acc: 0.7013 - val_loss: 0.9399 - val_acc: 0.6799\n","Epoch 21/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.8048 - acc: 0.6956 - val_loss: 0.8106 - val_acc: 0.6998\n","Epoch 22/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.7884 - acc: 0.6982 - val_loss: 1.0077 - val_acc: 0.6076\n","Epoch 23/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.8126 - acc: 0.6907 - val_loss: 0.9073 - val_acc: 0.6727\n","Epoch 24/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.8081 - acc: 0.6841 - val_loss: 0.7861 - val_acc: 0.6998\n","Epoch 25/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.8040 - acc: 0.6920 - val_loss: 0.8791 - val_acc: 0.7034\n","Epoch 26/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.7868 - acc: 0.7027 - val_loss: 0.8332 - val_acc: 0.6854\n","Epoch 27/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.7946 - acc: 0.6951 - val_loss: 0.8765 - val_acc: 0.6727\n","Epoch 28/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.7841 - acc: 0.7000 - val_loss: 0.9464 - val_acc: 0.6655\n","Epoch 29/30\n","226/226 [==============================] - 7s 29ms/step - loss: 0.7764 - acc: 0.7058 - val_loss: 0.7797 - val_acc: 0.7143\n","Epoch 30/30\n","226/226 [==============================] - 7s 30ms/step - loss: 0.7702 - acc: 0.7053 - val_loss: 0.8702 - val_acc: 0.6727\n"],"name":"stdout"}]},{"metadata":{"id":"-X20EPuL-hdi","colab_type":"code","outputId":"dc99be0b-12f2-43b7-bb61-6b75bdd57377","executionInfo":{"status":"ok","timestamp":1555849567943,"user_tz":-480,"elapsed":223258,"user":{"displayName":"楊傑","photoUrl":"","userId":"07428092554711625917"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"cell_type":"code","source":["test_path = \"D:/image_data/test\" \n","test_batches = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path, target_size=(32,32), batch_size=1, shuffle = False)\n","\n","predictions = model.predict_generator(test_batches, steps=test_batches.samples, verbose=0)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Found 2000 images belonging to 1 classes.\n"],"name":"stdout"}]},{"metadata":{"id":"Yty7I7olFs_p","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","\n","predicted_class_indices = np.argmax(predictions, axis=1)\n","test_filenames, test_labels = test_batches.filenames, predicted_class_indices\n","\n","# 處理檔名: 以斜線('\\\\'或'/')分開(.split)，回傳最後值(.pop), 由右邊用'.'分開取第二個值(index=1, 最右邊index=0為副檔名)\n","def getFileNameWithoutExtension(path):\n","  return path.split('\\\\').pop().split('/').pop().rsplit('.', 1)[0]\n","\n","test_filenames_list = []\n","for item in test_filenames:\n","  test_filenames_list.append(getFileNameWithoutExtension(item))\n","\n","test_labels_list = []\n","for item in test_labels:\n","  test_labels_list.append(str(item))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XHHClhY1NSuk","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","dataset1 = pd.DataFrame(test_filenames_list)\n","dataset1.columns=['id']\n","dataset2 = pd.DataFrame(test_labels_list)\n","dataset2.columns=['flower_class']\n","\n","submission = pd.concat([dataset1, dataset2], axis=1)\n","\n","submission.to_csv('D:/image_data/submission_3.csv', index = False)"],"execution_count":0,"outputs":[]}]}