{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Day_101-105_final_9_20190424_1.ipynb","version":"0.3.2","provenance":[{"file_id":"1h9DP_Wj2uLBGiINjGGeWMF2NNMCmVUpi","timestamp":1555837920550}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"Sxwq9MhD-hdN","colab_type":"code","outputId":"2373c0e1-f9d4-4e48-be51-75077d4fc339","executionInfo":{"status":"ok","timestamp":1556124719348,"user_tz":-480,"elapsed":7836,"user":{"displayName":"楊傑","photoUrl":"","userId":"07428092554711625917"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn import datasets\n","\n","from keras.applications.resnet50 import ResNet50 # 這是從 resnet_builder.py 中直接 import 撰寫好的 resnet 函數\n","from keras.models import Model\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"wF6bCJGX-hdT","colab_type":"text"},"cell_type":"markdown","source":["目錄tree:\"D:\\3_learn\\9_MachineLearning\\2_ML100-Days_Data\\Final\\image_data\"  \n","├── test/  \n","└── train/    \n","　　├── daisy/    \n","　　├── dandelion/    \n","　　├── rose/    \n","　　├── sunflower/    \n","　　└── tulip/"]},{"metadata":{"id":"BbHIKyqz-hdV","colab_type":"code","outputId":"ec272a2a-eddd-41df-cad3-acd67b6be648","executionInfo":{"status":"ok","timestamp":1556124720596,"user_tz":-480,"elapsed":9062,"user":{"displayName":"楊傑","photoUrl":"","userId":"07428092554711625917"}},"colab":{"base_uri":"https://localhost:8080/","height":167}},"cell_type":"code","source":["# 設定資料路徑\n","train_path = \"D:/image_data/train\" \n","test_path = \"D:/image_data/test\" \n","\n","# 影像大小\n","IMAGE_SIZE = (256, 256)\n","# 影像類別數，共有 5 個類別\n","NUM_CLASSES = 5\n","# 若 GPU 記憶體不足，可調降 batch size 或凍結更多層網路\n","BATCH_SIZE = 8\n","# 凍結網路層數\n","FREEZE_LAYERS = 2\n","# Epoch 數\n","NUM_EPOCHS = 120\n","# 模型輸出儲存的檔案\n","WEIGHTS_FINAL = 'model-resnet50-final.h5'\n","\n","# 圖形預處理\n","# image augmentation + 從directory feed資料\n","train_datagen = ImageDataGenerator(\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True)\n","\n","train_batches = train_datagen.flow_from_directory(\n","    train_path, target_size = IMAGE_SIZE, \n","    classes = ['daisy','dandelion','rose','sunflower','tulip'], \n","    batch_size = BATCH_SIZE,\n","    shuffle = True)\n","print(train_batches.image_shape)\n","\n","valid_datagen = ImageDataGenerator(\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2)\n","valid_batches = valid_datagen.flow_from_directory(\n","    train_path, target_size = IMAGE_SIZE, \n","    classes = ['daisy','dandelion','rose','sunflower','tulip'], \n","    batch_size = BATCH_SIZE,\n","    shuffle = True,\n","    subset = 'validation')\n","print(valid_batches.image_shape)\n","\n","for cls, idx in train_batches.class_indices.items():\n","    print('Class #{} = {}'.format(idx, cls))\n","\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Found 2823 images belonging to 5 classes.\n","(256, 256, 3)\n","Found 563 images belonging to 5 classes.\n","(256, 256, 3)\n","Class #0 = daisy\n","Class #1 = dandelion\n","Class #2 = rose\n","Class #3 = sunflower\n","Class #4 = tulip\n"],"name":"stdout"}]},{"metadata":{"id":"oaCI0ivs-hdb","colab_type":"code","outputId":"31f7088f-ce35-4624-fc54-6422f143f79e","executionInfo":{"status":"ok","timestamp":1556131857574,"user_tz":-480,"elapsed":7146023,"user":{"displayName":"楊傑","photoUrl":"","userId":"07428092554711625917"}},"colab":{"base_uri":"https://localhost:8080/","height":10521}},"cell_type":"code","source":["# 以訓練好的 ResNet50 為基礎來建立模型\n","# 捨棄 ResNet50 頂層的 fully connected layers\n","net = ResNet50(include_top = False, weights = 'imagenet', input_tensor = None,\n","               input_shape = (IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n","x = net.output\n","x = Flatten()(x)\n","\n","# 增加 DropOut layer\n","x = Dropout(0.5)(x)\n","\n","# 增加 Dense layer，以 softmax 產生個類別的機率值\n","output_layer = Dense(NUM_CLASSES, activation='softmax', name='softmax')(x)\n","\n","# 設定凍結與要進行訓練的網路層\n","model = Model(inputs = net.input, outputs=output_layer)\n","for layer in model.layers[:FREEZE_LAYERS]:\n","    layer.trainable = False\n","for layer in model.layers[FREEZE_LAYERS:]:\n","    layer.trainable = True\n","    \n","model.compile(loss = 'categorical_crossentropy',\n","              optimizer = Adam(lr=1e-5),\n","              metrics = ['accuracy'])\n","\n","model.summary()\n","\n","STEP_SIZE_TRAIN = train_batches.samples // train_batches.batch_size\n","STEP_SIZE_VALID = valid_batches.samples // valid_batches.batch_size\n","\n","history = model.fit_generator(generator = train_batches, \n","                                  steps_per_epoch = STEP_SIZE_TRAIN, \n","                                  validation_data = valid_batches,\n","                                  validation_steps = STEP_SIZE_VALID, \n","                                  epochs = NUM_EPOCHS, verbose = 1)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1 (Conv2D)                  (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","bn_conv1 (BatchNormalization)   (None, 128, 128, 64) 256         conv1[0][0]                      \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 128, 128, 64) 0           bn_conv1[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","res2a_branch2a (Conv2D)         (None, 64, 64, 64)   4160        max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","bn2a_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 64, 64, 64)   0           bn2a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","bn2a_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 64, 64, 64)   0           bn2a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","res2a_branch1 (Conv2D)          (None, 64, 64, 256)  16640       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","bn2a_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn2a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res2a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 64, 64, 256)  0           bn2a_branch2c[0][0]              \n","                                                                 bn2a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 64, 64, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","res2b_branch2a (Conv2D)         (None, 64, 64, 64)   16448       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 64, 64, 64)   0           bn2b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 64, 64, 64)   0           bn2b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 64, 64, 256)  0           bn2b_branch2c[0][0]              \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 64, 64, 256)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","res2c_branch2a (Conv2D)         (None, 64, 64, 64)   16448       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 64, 64, 64)   0           bn2c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 64, 64, 64)   0           bn2c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 64, 64, 256)  0           bn2c_branch2c[0][0]              \n","                                                                 activation_7[0][0]               \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 64, 64, 256)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","res3a_branch2a (Conv2D)         (None, 32, 32, 128)  32896       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 32, 32, 128)  0           bn3a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_11[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 32, 32, 128)  0           bn3a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch1 (Conv2D)          (None, 32, 32, 512)  131584      activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn3a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res3a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 32, 32, 512)  0           bn3a_branch2c[0][0]              \n","                                                                 bn3a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 32, 32, 512)  0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","res3b_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 32, 32, 128)  0           bn3b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_14[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 32, 32, 128)  0           bn3b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 32, 32, 512)  0           bn3b_branch2c[0][0]              \n","                                                                 activation_13[0][0]              \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 32, 32, 512)  0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","res3c_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 32, 32, 128)  0           bn3c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_17[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 32, 32, 128)  0           bn3c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 32, 32, 512)  0           bn3c_branch2c[0][0]              \n","                                                                 activation_16[0][0]              \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 32, 32, 512)  0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","res3d_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 32, 32, 128)  0           bn3d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 32, 32, 128)  0           bn3d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 32, 32, 512)  0           bn3d_branch2c[0][0]              \n","                                                                 activation_19[0][0]              \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 32, 32, 512)  0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","res4a_branch2a (Conv2D)         (None, 16, 16, 256)  131328      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 16, 16, 256)  0           bn4a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 16, 16, 256)  0           bn4a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch1 (Conv2D)          (None, 16, 16, 1024) 525312      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn4a_branch1 (BatchNormalizatio (None, 16, 16, 1024) 4096        res4a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 16, 16, 1024) 0           bn4a_branch2c[0][0]              \n","                                                                 bn4a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 16, 16, 1024) 0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","res4b_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 16, 16, 256)  0           bn4b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_26[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 16, 16, 256)  0           bn4b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_27[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 16, 16, 1024) 0           bn4b_branch2c[0][0]              \n","                                                                 activation_25[0][0]              \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 16, 16, 1024) 0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","res4c_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 16, 16, 256)  0           bn4c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_29[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 16, 16, 256)  0           bn4c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_30[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 16, 16, 1024) 0           bn4c_branch2c[0][0]              \n","                                                                 activation_28[0][0]              \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 16, 16, 1024) 0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","res4d_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 16, 16, 256)  0           bn4d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_32[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 16, 16, 256)  0           bn4d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_33[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 16, 16, 1024) 0           bn4d_branch2c[0][0]              \n","                                                                 activation_31[0][0]              \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 16, 16, 1024) 0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","res4e_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_34[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4e_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 16, 16, 256)  0           bn4e_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_35[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4e_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 16, 16, 256)  0           bn4e_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4e_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 16, 16, 1024) 0           bn4e_branch2c[0][0]              \n","                                                                 activation_34[0][0]              \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 16, 16, 1024) 0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","res4f_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4f_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 16, 16, 256)  0           bn4f_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4f_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 16, 16, 256)  0           bn4f_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_39[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4f_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 16, 16, 1024) 0           bn4f_branch2c[0][0]              \n","                                                                 activation_37[0][0]              \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 16, 16, 1024) 0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","res5a_branch2a (Conv2D)         (None, 8, 8, 512)    524800      activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 8, 8, 512)    0           bn5a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_41[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 8, 8, 512)    0           bn5a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_42[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch1 (Conv2D)          (None, 8, 8, 2048)   2099200     activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn5a_branch1 (BatchNormalizatio (None, 8, 8, 2048)   8192        res5a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 8, 8, 2048)   0           bn5a_branch2c[0][0]              \n","                                                                 bn5a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 8, 8, 2048)   0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","res5b_branch2a (Conv2D)         (None, 8, 8, 512)    1049088     activation_43[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 8, 8, 512)    0           bn5b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_44[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 8, 8, 512)    0           bn5b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_45[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 8, 8, 2048)   0           bn5b_branch2c[0][0]              \n","                                                                 activation_43[0][0]              \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 8, 8, 2048)   0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","res5c_branch2a (Conv2D)         (None, 8, 8, 512)    1049088     activation_46[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 8, 8, 512)    0           bn5c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_47[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 8, 8, 512)    0           bn5c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_48[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 8, 8, 2048)   0           bn5c_branch2c[0][0]              \n","                                                                 activation_46[0][0]              \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 8, 8, 2048)   0           add_16[0][0]                     \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 131072)       0           activation_49[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 131072)       0           flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","softmax (Dense)                 (None, 5)            655365      dropout_1[0][0]                  \n","==================================================================================================\n","Total params: 24,243,077\n","Trainable params: 24,189,957\n","Non-trainable params: 53,120\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/120\n","352/352 [==============================] - 123s 351ms/step - loss: 2.4734 - acc: 0.3857 - val_loss: 0.9603 - val_acc: 0.6964\n","Epoch 2/120\n","352/352 [==============================] - 60s 170ms/step - loss: 1.4985 - acc: 0.6064 - val_loss: 0.6773 - val_acc: 0.7802\n","Epoch 3/120\n","352/352 [==============================] - 60s 170ms/step - loss: 1.1249 - acc: 0.6934 - val_loss: 0.5185 - val_acc: 0.8324\n","Epoch 4/120\n","352/352 [==============================] - 60s 170ms/step - loss: 0.9586 - acc: 0.7446 - val_loss: 0.4071 - val_acc: 0.8739\n","Epoch 5/120\n","352/352 [==============================] - 60s 170ms/step - loss: 0.8697 - acc: 0.7769 - val_loss: 0.3540 - val_acc: 0.8757\n","Epoch 6/120\n","352/352 [==============================] - 60s 170ms/step - loss: 0.7708 - acc: 0.7914 - val_loss: 0.2728 - val_acc: 0.9063\n","Epoch 7/120\n","352/352 [==============================] - 60s 170ms/step - loss: 0.6739 - acc: 0.8146 - val_loss: 0.2618 - val_acc: 0.9099\n","Epoch 8/120\n","352/352 [==============================] - 60s 170ms/step - loss: 0.6021 - acc: 0.8235 - val_loss: 0.2316 - val_acc: 0.9261\n","Epoch 9/120\n","352/352 [==============================] - 60s 170ms/step - loss: 0.5949 - acc: 0.8394 - val_loss: 0.1997 - val_acc: 0.9261\n","Epoch 10/120\n","352/352 [==============================] - 60s 170ms/step - loss: 0.5315 - acc: 0.8476 - val_loss: 0.1805 - val_acc: 0.9315\n","Epoch 11/120\n","352/352 [==============================] - 60s 170ms/step - loss: 0.5419 - acc: 0.8491 - val_loss: 0.1607 - val_acc: 0.9441\n","Epoch 12/120\n","352/352 [==============================] - 60s 170ms/step - loss: 0.4773 - acc: 0.8583 - val_loss: 0.1518 - val_acc: 0.9459\n","Epoch 13/120\n","352/352 [==============================] - 60s 170ms/step - loss: 0.4423 - acc: 0.8665 - val_loss: 0.1383 - val_acc: 0.9441\n","Epoch 14/120\n","352/352 [==============================] - 60s 170ms/step - loss: 0.3665 - acc: 0.8899 - val_loss: 0.1255 - val_acc: 0.9568\n","Epoch 15/120\n","352/352 [==============================] - 60s 170ms/step - loss: 0.3723 - acc: 0.8902 - val_loss: 0.1200 - val_acc: 0.9586\n","Epoch 16/120\n","352/352 [==============================] - 60s 170ms/step - loss: 0.3576 - acc: 0.8920 - val_loss: 0.0932 - val_acc: 0.9712\n","Epoch 17/120\n","352/352 [==============================] - 60s 170ms/step - loss: 0.3217 - acc: 0.9002 - val_loss: 0.1236 - val_acc: 0.9495\n","Epoch 18/120\n","352/352 [==============================] - 60s 170ms/step - loss: 0.2967 - acc: 0.9062 - val_loss: 0.1037 - val_acc: 0.9568\n","Epoch 19/120\n","352/352 [==============================] - 60s 169ms/step - loss: 0.2869 - acc: 0.9116 - val_loss: 0.0876 - val_acc: 0.9694\n","Epoch 20/120\n","352/352 [==============================] - 59s 168ms/step - loss: 0.2685 - acc: 0.9137 - val_loss: 0.0928 - val_acc: 0.9676\n","Epoch 21/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.2685 - acc: 0.9144 - val_loss: 0.0542 - val_acc: 0.9802\n","Epoch 22/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.2384 - acc: 0.9207 - val_loss: 0.0962 - val_acc: 0.9640\n","Epoch 23/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.2190 - acc: 0.9292 - val_loss: 0.0567 - val_acc: 0.9784\n","Epoch 24/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.2327 - acc: 0.9307 - val_loss: 0.0669 - val_acc: 0.9712\n","Epoch 25/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.1769 - acc: 0.9474 - val_loss: 0.0476 - val_acc: 0.9820\n","Epoch 26/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.1777 - acc: 0.9460 - val_loss: 0.0591 - val_acc: 0.9802\n","Epoch 27/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.1557 - acc: 0.9446 - val_loss: 0.0610 - val_acc: 0.9802\n","Epoch 28/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.1795 - acc: 0.9464 - val_loss: 0.0409 - val_acc: 0.9910\n","Epoch 29/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.1621 - acc: 0.9463 - val_loss: 0.0398 - val_acc: 0.9892\n","Epoch 30/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.1578 - acc: 0.9492 - val_loss: 0.0383 - val_acc: 0.9856\n","Epoch 31/120\n","352/352 [==============================] - 58s 166ms/step - loss: 0.1386 - acc: 0.9567 - val_loss: 0.0238 - val_acc: 0.9910\n","Epoch 32/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.1546 - acc: 0.9510 - val_loss: 0.0270 - val_acc: 0.9910\n","Epoch 33/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.1092 - acc: 0.9609 - val_loss: 0.0386 - val_acc: 0.9820\n","Epoch 34/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.1107 - acc: 0.9644 - val_loss: 0.0211 - val_acc: 0.9928\n","Epoch 35/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0974 - acc: 0.9663 - val_loss: 0.0180 - val_acc: 0.9910\n","Epoch 36/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0971 - acc: 0.9627 - val_loss: 0.0233 - val_acc: 0.9874\n","Epoch 37/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.1041 - acc: 0.9634 - val_loss: 0.0119 - val_acc: 0.9982\n","Epoch 38/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0840 - acc: 0.9687 - val_loss: 0.0110 - val_acc: 0.9946\n","Epoch 39/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0747 - acc: 0.9737 - val_loss: 0.0325 - val_acc: 0.9892\n","Epoch 40/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0789 - acc: 0.9712 - val_loss: 0.0278 - val_acc: 0.9910\n","Epoch 41/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0894 - acc: 0.9733 - val_loss: 0.0135 - val_acc: 0.9946\n","Epoch 42/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0919 - acc: 0.9727 - val_loss: 0.0162 - val_acc: 0.9946\n","Epoch 43/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.1053 - acc: 0.9712 - val_loss: 0.0063 - val_acc: 0.9982\n","Epoch 44/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0616 - acc: 0.9766 - val_loss: 0.0131 - val_acc: 0.9928\n","Epoch 45/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0829 - acc: 0.9744 - val_loss: 0.0267 - val_acc: 0.9946\n","Epoch 46/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0662 - acc: 0.9798 - val_loss: 0.0160 - val_acc: 0.9946\n","Epoch 47/120\n","352/352 [==============================] - 58s 166ms/step - loss: 0.0815 - acc: 0.9759 - val_loss: 0.0213 - val_acc: 0.9946\n","Epoch 48/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0598 - acc: 0.9830 - val_loss: 0.0039 - val_acc: 0.9982\n","Epoch 49/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0601 - acc: 0.9790 - val_loss: 0.0198 - val_acc: 0.9946\n","Epoch 50/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0641 - acc: 0.9779 - val_loss: 0.0046 - val_acc: 1.0000\n","Epoch 51/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0573 - acc: 0.9794 - val_loss: 0.0041 - val_acc: 0.9982\n","Epoch 52/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0505 - acc: 0.9826 - val_loss: 0.0053 - val_acc: 0.9982\n","Epoch 53/120\n","352/352 [==============================] - 58s 166ms/step - loss: 0.0586 - acc: 0.9790 - val_loss: 0.0123 - val_acc: 0.9946\n","Epoch 54/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0518 - acc: 0.9847 - val_loss: 0.0014 - val_acc: 1.0000\n","Epoch 55/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0698 - acc: 0.9794 - val_loss: 0.0164 - val_acc: 0.9964\n","Epoch 56/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0447 - acc: 0.9840 - val_loss: 0.0128 - val_acc: 0.9946\n","Epoch 57/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0578 - acc: 0.9847 - val_loss: 0.0053 - val_acc: 0.9964\n","Epoch 58/120\n","352/352 [==============================] - 58s 166ms/step - loss: 0.0487 - acc: 0.9840 - val_loss: 0.0073 - val_acc: 0.9982\n","Epoch 59/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0396 - acc: 0.9847 - val_loss: 0.0049 - val_acc: 0.9982\n","Epoch 60/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0487 - acc: 0.9846 - val_loss: 0.0065 - val_acc: 0.9982\n","Epoch 61/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0374 - acc: 0.9858 - val_loss: 3.6470e-04 - val_acc: 1.0000\n","Epoch 62/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0632 - acc: 0.9812 - val_loss: 0.0091 - val_acc: 0.9946\n","Epoch 63/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0499 - acc: 0.9819 - val_loss: 0.0110 - val_acc: 0.9982\n","Epoch 64/120\n","352/352 [==============================] - 58s 166ms/step - loss: 0.0447 - acc: 0.9872 - val_loss: 0.0067 - val_acc: 0.9964\n","Epoch 65/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0509 - acc: 0.9837 - val_loss: 0.0018 - val_acc: 1.0000\n","Epoch 66/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0309 - acc: 0.9901 - val_loss: 0.0038 - val_acc: 0.9982\n","Epoch 67/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0411 - acc: 0.9879 - val_loss: 0.0033 - val_acc: 1.0000\n","Epoch 68/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0398 - acc: 0.9883 - val_loss: 0.0069 - val_acc: 0.9964\n","Epoch 69/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0394 - acc: 0.9901 - val_loss: 0.0064 - val_acc: 0.9964\n","Epoch 70/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0463 - acc: 0.9851 - val_loss: 0.0078 - val_acc: 0.9982\n","Epoch 71/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0353 - acc: 0.9876 - val_loss: 0.0021 - val_acc: 1.0000\n","Epoch 72/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0307 - acc: 0.9890 - val_loss: 9.2608e-04 - val_acc: 1.0000\n","Epoch 73/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0415 - acc: 0.9883 - val_loss: 0.0209 - val_acc: 0.9946\n","Epoch 74/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0300 - acc: 0.9911 - val_loss: 0.0038 - val_acc: 0.9982\n","Epoch 75/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0290 - acc: 0.9890 - val_loss: 0.0031 - val_acc: 0.9982\n","Epoch 76/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0419 - acc: 0.9854 - val_loss: 0.0171 - val_acc: 0.9964\n","Epoch 77/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0275 - acc: 0.9911 - val_loss: 0.0012 - val_acc: 1.0000\n","Epoch 78/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0418 - acc: 0.9897 - val_loss: 0.0159 - val_acc: 0.9946\n","Epoch 79/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0288 - acc: 0.9918 - val_loss: 0.0048 - val_acc: 0.9982\n","Epoch 80/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0399 - acc: 0.9911 - val_loss: 0.0142 - val_acc: 0.9964\n","Epoch 81/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0278 - acc: 0.9908 - val_loss: 0.0019 - val_acc: 1.0000\n","Epoch 82/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0280 - acc: 0.9925 - val_loss: 0.0030 - val_acc: 0.9982\n","Epoch 83/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0386 - acc: 0.9883 - val_loss: 0.0020 - val_acc: 1.0000\n","Epoch 84/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0354 - acc: 0.9865 - val_loss: 0.0016 - val_acc: 0.9982\n","Epoch 85/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0188 - acc: 0.9925 - val_loss: 0.0021 - val_acc: 0.9982\n","Epoch 86/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0247 - acc: 0.9908 - val_loss: 0.0029 - val_acc: 0.9982\n","Epoch 87/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0322 - acc: 0.9890 - val_loss: 4.9339e-04 - val_acc: 1.0000\n","Epoch 88/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0196 - acc: 0.9922 - val_loss: 0.0044 - val_acc: 0.9964\n","Epoch 89/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0239 - acc: 0.9929 - val_loss: 0.0012 - val_acc: 1.0000\n","Epoch 90/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0303 - acc: 0.9886 - val_loss: 0.0017 - val_acc: 0.9982\n","Epoch 91/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0236 - acc: 0.9929 - val_loss: 0.0020 - val_acc: 1.0000\n","Epoch 92/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0240 - acc: 0.9929 - val_loss: 6.0917e-04 - val_acc: 1.0000\n","Epoch 93/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0288 - acc: 0.9893 - val_loss: 0.0098 - val_acc: 0.9946\n","Epoch 94/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0316 - acc: 0.9922 - val_loss: 0.0156 - val_acc: 0.9946\n","Epoch 95/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0230 - acc: 0.9925 - val_loss: 6.9560e-04 - val_acc: 1.0000\n","Epoch 96/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0189 - acc: 0.9940 - val_loss: 1.5345e-04 - val_acc: 1.0000\n","Epoch 97/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0333 - acc: 0.9908 - val_loss: 0.0122 - val_acc: 0.9964\n","Epoch 98/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0181 - acc: 0.9936 - val_loss: 0.0017 - val_acc: 0.9982\n","Epoch 99/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0300 - acc: 0.9911 - val_loss: 0.0051 - val_acc: 0.9982\n","Epoch 100/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0250 - acc: 0.9908 - val_loss: 3.8784e-04 - val_acc: 1.0000\n","Epoch 101/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0237 - acc: 0.9943 - val_loss: 0.0097 - val_acc: 0.9964\n","Epoch 102/120\n","352/352 [==============================] - 58s 166ms/step - loss: 0.0278 - acc: 0.9915 - val_loss: 0.0131 - val_acc: 0.9964\n","Epoch 103/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0157 - acc: 0.9947 - val_loss: 0.0022 - val_acc: 1.0000\n","Epoch 104/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0187 - acc: 0.9915 - val_loss: 0.0016 - val_acc: 1.0000\n","Epoch 105/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0221 - acc: 0.9936 - val_loss: 5.2918e-04 - val_acc: 1.0000\n","Epoch 106/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0230 - acc: 0.9932 - val_loss: 0.0013 - val_acc: 0.9982\n","Epoch 107/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0247 - acc: 0.9918 - val_loss: 0.0073 - val_acc: 0.9964\n","Epoch 108/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0216 - acc: 0.9936 - val_loss: 0.0045 - val_acc: 0.9982\n","Epoch 109/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0213 - acc: 0.9933 - val_loss: 2.9328e-04 - val_acc: 1.0000\n","Epoch 110/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0217 - acc: 0.9929 - val_loss: 4.3036e-04 - val_acc: 1.0000\n","Epoch 111/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0227 - acc: 0.9929 - val_loss: 5.0081e-04 - val_acc: 1.0000\n","Epoch 112/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0236 - acc: 0.9925 - val_loss: 0.0017 - val_acc: 0.9982\n","Epoch 113/120\n","352/352 [==============================] - 59s 167ms/step - loss: 0.0354 - acc: 0.9918 - val_loss: 2.9779e-04 - val_acc: 1.0000\n","Epoch 114/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0184 - acc: 0.9940 - val_loss: 0.0018 - val_acc: 0.9982\n","Epoch 115/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0182 - acc: 0.9929 - val_loss: 5.6819e-04 - val_acc: 1.0000\n","Epoch 116/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0209 - acc: 0.9925 - val_loss: 2.7469e-04 - val_acc: 1.0000\n","Epoch 117/120\n","352/352 [==============================] - 58s 166ms/step - loss: 0.0205 - acc: 0.9922 - val_loss: 0.0082 - val_acc: 0.9982\n","Epoch 118/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0182 - acc: 0.9943 - val_loss: 8.5189e-05 - val_acc: 1.0000\n","Epoch 119/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0192 - acc: 0.9950 - val_loss: 4.0719e-05 - val_acc: 1.0000\n","Epoch 120/120\n","352/352 [==============================] - 59s 166ms/step - loss: 0.0211 - acc: 0.9940 - val_loss: 0.0012 - val_acc: 1.0000\n"],"name":"stdout"}]},{"metadata":{"id":"-X20EPuL-hdi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"4b95cd19-befe-41f7-95da-d9ee1876a01d","executionInfo":{"status":"ok","timestamp":1556131887932,"user_tz":-480,"elapsed":7176362,"user":{"displayName":"楊傑","photoUrl":"","userId":"07428092554711625917"}}},"cell_type":"code","source":["test_path = \"D:/image_data/test\" \n","test_batches = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path, target_size=IMAGE_SIZE, batch_size=1, shuffle = False)\n","\n","predictions = model.predict_generator(test_batches, steps=test_batches.samples, verbose=1)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Found 2000 images belonging to 1 classes.\n","2000/2000 [==============================] - 30s 15ms/step\n"],"name":"stdout"}]},{"metadata":{"id":"Yty7I7olFs_p","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","\n","predicted_class_indices = np.argmax(predictions, axis=1)\n","test_filenames, test_labels = test_batches.filenames, predicted_class_indices\n","\n","# 處理檔名: 以斜線('\\\\'或'/')分開(.split)，回傳最後值(.pop), 由右邊用'.'分開取第二個值(index=1, 最右邊index=0為副檔名)\n","def getFileNameWithoutExtension(path):\n","  return path.split('\\\\').pop().split('/').pop().rsplit('.', 1)[0]\n","\n","test_filenames_list = []\n","for item in test_filenames:\n","  test_filenames_list.append(getFileNameWithoutExtension(item))\n","\n","test_labels_list = []\n","for item in test_labels:\n","  test_labels_list.append(str(item))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XHHClhY1NSuk","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","dataset1 = pd.DataFrame(test_filenames_list)\n","dataset1.columns=['id']\n","dataset2 = pd.DataFrame(test_labels_list)\n","dataset2.columns=['flower_class']\n","\n","submission = pd.concat([dataset1, dataset2], axis=1)\n","\n","submission.to_csv('D:/image_data/submission_9.csv', index = False)"],"execution_count":0,"outputs":[]}]}